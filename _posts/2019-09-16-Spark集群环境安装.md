---
layout: "post"
title: "Spark集群环境安装"
date: "2019-09-16 11:52"
categories: Hadoop
description: Spark集群环境安装
tags: Hadoop Spark
---

* content
{:toc}

<div class="postImg" style="background-image:url(http://carforeasy.cn/Spark集群环境安装-f99e0f8b.png)" ></div>
> “本文介绍Spark集群环境搭建，在之前安装好的Hadoop 3集群之上搭建Spark环境。”





## 1. 环境

### 1.1 设置主机名，配置hosts文件

  准备3台虚拟机(CentOS 7)，一台 master，两台 slave。master 作为Spark Master，slave 均作为Spark Slave。

  ```
  master : master.test.com
  slave1 : node1.test.com
  slave2 : node2.test.com
  ```

  由于之前安装了Hadoop环境，/etc/hosts文件、NTP配置等不再重复。

### 1.2 设置环境变量
  系统中安装jdk，将下载的Spark 压缩包解压至/opt/spark，之后配置环境变量：

  ```
  mkdir -p /opt/spark
  tar --strip-components=1 -zxvf spark-2.4.4-bin-hadoop2.7.tgz -C /opt/spark/
  ```

  + /etc/profile中添加

  ```
  #java
  export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
  export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
  export PATH=$PATH:$JAVA_HOME/bin

  #hadoop
  export HADOOP_HOME=/opt/hadoop
  export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

  #spark
  export SPARK_HOME=/opt/spark
  export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
  ```

## 2. Spark配置



### 2.1 新建用户及用户组

  为spark组件建立单独的用户spark, 加入hadoop组

  ```
  useradd spark -g hadoop
  chown -R spark:hadoop /opt/spark
  ```


### 2.2 创建相关目录


+ 新建日志目录

  ```
  mkdir /var/log/spark
  chown spark:hadoop /var/log/spark
  chmod -R 770 /var/log/spark

  ```

+ 新建pid目录

  ```
  mkdir /var/run/spark
  chown spark:hadoop /var/run/spark
  chmod -R 770 /var/run/spark

  ```

### 2.3 配置文件

共需要配置/opt/spark/conf/目录下的2个文件，分别是
+ spark-env.sh
+ slaves



#### 2.3.1 spark-env.sh

```
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
export HADOOP_HOME=/opt/hadoop/

export SPARK_HOME=/opt/spark
export SPARK_MASTER_IP=master.test.com
export SPARK_WORKER_MEMORY=1g
export SPARK_WORKER_CORES=2
export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop

export SPARK_PID_DIR=/var/run/spark
export SPARK_LOG_DIR=/var/log/spark
```

#### 2.3.2 slaves

```
node1.test.com
node2.test.com

```

## 3. 集群操作测试

### 3.1 启动集群

+ 1. 启动master

  ```
  su spark -c 'start-master.sh'
  ```
+ 2. 启动slave
  ```
  su spark -c 'start-slave.sh spark://master.test.com:7077'
  ```

### 3.2 停止集群

  + 1. 停止master

    ```
    su spark -c 'stop-master.sh'
    ```
  + 2. 停止slave
    ```
    su spark -c 'stop-slave.sh'
    ```

### 3.3 WebUI访问  

+ Spark UI
  [http://master.test.com:8080/](http://master.test.com:8080/)

  ![](http://carforeasy.cn/Spark集群环境安装-66a3bdc2.png)


### 3.4 Spark on YARN

Spark程序由Master还是YARN来调度执行，是由Spark程序在提交时决定的。以计算圆周率Pi的示例程序为例，Spark程序的提交方式是：

```
$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \
    --master spark://<active-master-ip>:<port> \
    lib/spark-examples*.jar \
    10

```
其中参数--master决定调度方式：如果该参数的值以spark://开头，则使用Spark自己的Master节点来调度；如果其值是yarn-client或yarn-cluster，则是使用YARN来调度，而YARN的具体地址会从前面配置的Hadoop配置目录下的配置文件中得到。

YARN调度有如下两种模式。

+ yarn-cluster模式。
  YARN会先在集群的某个节点上为Spark程序启动一个称作Master的进程，然后Driver程序会运行在这个Master进程内部，由这个Master进程来启动Driver程序，客户端完成提交的步骤后就可以退出，不需要等待Spark程序运行结束。这是一种非常适合生产环境的运行方式。
+ yarn-client模式。
  跟yarn-cluster模式类似，这也有一个Master进程，但Driver程序不会运行在Master进程内部，而是运行在本地，只是通过Master来申请资源，直至程序运行结束。这种模式非常适合需要交互的计算。



## 4. 参考链接

+ [Hadoop 和 Spark 集群安装](https://www.jianshu.com/p/6391cae87527)
+ [Spark 的三种集群 deploy 模式对比](https://juejin.im/entry/575239e16be3ff006be189f4)
+ [喜大普奔：Spark on kubernetes](https://ieevee.com/tech/2017/08/31/spark-on-k8s.html)
+ [Spark on Yarn](https://blog.csdn.net/lsshlsw/article/details/41787537)
